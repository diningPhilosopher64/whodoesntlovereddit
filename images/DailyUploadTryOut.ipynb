{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16f7f114-a2fd-4492-bdb1-1428a0c311bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, boto3, pandas as pd, os, sys, pprint\n",
    "from pathlib import Path\n",
    "pp = pprint.PrettyPrinter(indent=2, compact=True, width=80)\n",
    "\n",
    "# from entities.RedditAccount import RedditAccount\n",
    "from entities.DailyUpload import DailyUpload\n",
    "\n",
    "#TODO: Change path accordingly in handler\n",
    "\n",
    "\n",
    "# Making the current directory in which this file is in discoverable to python.\n",
    "# Commenting it here because it will not work in jupyter notebook. It will work in lambda though.\n",
    "#sys.path.append(os.path.join(os.path.dirname(__file__)))\n",
    "\n",
    "# Below should be used only in jupyter notebook\n",
    "sys.path.append('./')\n",
    "\n",
    "\n",
    "REDDIT_AUTH_URL = 'https://www.reddit.com/api/v1/access_token'\n",
    "REDDIT_ACCOUNTS_TABLE_NAME = 'RedditAccountsTable-dev'\n",
    "DAILY_UPLOADS_TABLE = \"DailyUploadsTable-dev\"\n",
    "REDDIT_API_URL_TOP = \"https://oauth.reddit.com/r/placeholder_value/top\"\n",
    "REDDIT_API_URL_SORT = \"https://oauth.reddit.com/r/placeholder_value/sort\"\n",
    "\n",
    "ddb = boto3.client(\"dynamodb\", region_name=\"ap-south-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b901c5f3-2d8e-43c3-84c1-03d38753ebc7",
   "metadata": {},
   "source": [
    "# Daily Upload Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf9194a4-bff5-4596-a510-69dc6056731d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# import pandas as pd\n",
    "\n",
    "import ddb_helpers\n",
    "\n",
    "\n",
    "class DailyUpload:\n",
    "    post_keys_to_keep = [\n",
    "        \"title\",\n",
    "        \"url\",\n",
    "        \"upvote_ratio\",\n",
    "        \"ups\",\n",
    "        \"author\",\n",
    "        \"name\",\n",
    "        \"total_awards_received\",\n",
    "    ]\n",
    "\n",
    "    def __init__(self, subreddit) -> None:\n",
    "        self.subreddit = subreddit\n",
    "        self.date = str(datetime.today().date())  ## Of the format yyyy-mm-dd\n",
    "        self.total_duration = 0\n",
    "        self.urls = []\n",
    "        # self.df_top = pd.DataFrame()\n",
    "        self.latest_post = None\n",
    "        self.eligible_posts = []\n",
    "\n",
    "    # Renamed from date_subreddit_key()\n",
    "    def key(self) -> dict:\n",
    "        \"\"\"Returns a dictionary with date as PK, subreddit as SK.\n",
    "\n",
    "        Returns:\n",
    "            Dict: Containing serialized subreddit and date\n",
    "        \"\"\"\n",
    "\n",
    "        return {\n",
    "            \"PK\": DailyUpload.__serialize_date(self.date),\n",
    "            \"SK\": DailyUpload.__serialize_subreddit(self.subreddit),\n",
    "        }\n",
    "\n",
    "    # def subreddit_date_key(self) -> dict:\n",
    "    #     \"\"\"Returns a dictionary with subreddit as PK date as SK.\n",
    "\n",
    "    #     Returns:\n",
    "    #         Dict: Containing serialized subreddit and date.\n",
    "    #     \"\"\"\n",
    "    # return {\"PK\": self.__serialize_subreddit(), \"SK\": self.__serialize_date()}\n",
    "\n",
    "    # Renamed from serialize_date_subreddit()\n",
    "    def serialize_to_item(self):\n",
    "        \"\"\"Serializes member variable data of this object for the access pattern:\n",
    "        date-Partition Key\n",
    "        subreddit- Sort Key\n",
    "\n",
    "        Returns:\n",
    "            Dict: Ready to be used by boto3 to insert item into DynamoDB.\n",
    "        \"\"\"\n",
    "        item = self.key()\n",
    "        item[\"posts\"] = DailyUpload.__serialize_posts(self.eligible_posts)\n",
    "        return item\n",
    "\n",
    "    @staticmethod\n",
    "    def __removed_post_is_worthy(post):\n",
    "        if post[\"removed_by\"] or post[\"removal_reason\"]:\n",
    "            if post[\"num_comments\"] > 5 and post[\"score\"] > 10:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    @staticmethod\n",
    "    def __is_eligible(post):\n",
    "        if (\n",
    "            post[\"is_video\"]\n",
    "            and post[\"ups\"] > 0\n",
    "            and post[\"num_comments\"] > 0\n",
    "            and not post[\"over_18\"]\n",
    "            and not post[\"stickied\"]\n",
    "        ):\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def parse_posts(self, posts):\n",
    "        \"\"\"Parse posts and insert into a dataframe.\n",
    "        The last parsed post will updated in a member variable.\n",
    "\n",
    "        Args:\n",
    "            posts (list): List of posts from reddit API\n",
    "        \"\"\"\n",
    "        posts = posts[\"data\"][\"children\"]\n",
    "        for post in posts:\n",
    "            post = post[\"data\"]\n",
    "            self.latest_post = post\n",
    "\n",
    "            if DailyUpload.__is_eligible(post) and DailyUpload.__removed_post_is_worthy(\n",
    "                post\n",
    "            ):\n",
    "\n",
    "                temp = {key: post[key] for key in DailyUpload.post_keys_to_keep}\n",
    "                self.eligible_posts.append(temp)\n",
    "                self.total_duration += int(post[\"media\"][\"reddit_video\"][\"duration\"])\n",
    "                # self.df_top = self.df_top.append(\n",
    "                #     {\n",
    "                #         \"title\": post[\"title\"],\n",
    "                #         \"upvote_ratio\": post[\"upvote_ratio\"],\n",
    "                #         \"ups\": post[\"ups\"],\n",
    "                #         \"downs\": post[\"downs\"],\n",
    "                #         \"score\": post[\"score\"],\n",
    "                #         \"url\": post[\"url\"],\n",
    "                #     },\n",
    "                #     ignore_index=True,\n",
    "                # )\n",
    "\n",
    "    # def sort_and_update_urls(self):\n",
    "    #     self.df_top = self.df_top.sort_values(\n",
    "    #         [\"score\", \"total_awards_received\", \"ups\", \"upvote_ratio\"],\n",
    "    #         ascending=False,\n",
    "    #         axis=0,\n",
    "    #     )\n",
    "\n",
    "    # self.urls = self.urls + self.df_top[\"url\"].tolist()\n",
    "\n",
    "    # def serialize_subreddit_date(self):\n",
    "    #     item = self.subreddit_date_key()\n",
    "    #     item[\"total_duration\"] = self.__serialize_total_duration()\n",
    "    #     return item\n",
    "\n",
    "    # def __serialize_urls(self):\n",
    "    #     serialized_urls = {\"L\": [{\"S\": url} for url in self.urls]}\n",
    "    #     return serialized_urls\n",
    "\n",
    "    #  post[\"title\"],\n",
    "    #                     post[\"upvote_ratio\"],\n",
    "    #                     post[\"ups\"],\n",
    "    #                     post[\"score\"],\n",
    "    #                     post[\"url\"],\n",
    "    #                     post[\"author\"],\n",
    "\n",
    "    @staticmethod\n",
    "    def __serialize_posts(posts):\n",
    "        serialized_posts = {\"L\": [DailyUpload.__serialize_post(post) for post in posts]}\n",
    "\n",
    "        return serialized_posts\n",
    "\n",
    "    @staticmethod\n",
    "    def __serialize_post(post):\n",
    "        serialized_post = {\"M\": {}}\n",
    "\n",
    "        for key in DailyUpload.post_keys_to_keep:\n",
    "            serialized_post[\"M\"][key] = {\n",
    "                ddb_helpers.get_datatype(post[key]): str(post[key])\n",
    "            }\n",
    "\n",
    "        return serialized_post\n",
    "\n",
    "    @staticmethod\n",
    "    def __serialize_subreddit(subreddit):\n",
    "        return {\"S\": subreddit}\n",
    "\n",
    "    # def __serialize_total_duration(self):\n",
    "    #     return {\"N\": str(self.total_duration)}\n",
    "\n",
    "    @staticmethod\n",
    "    def __serialize_date(date):\n",
    "        return {\"S\": date}\n",
    "\n",
    "    def deserialize_date_subreddit(item):\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def deserialize_PK_SK_count(item):\n",
    "        deserialized_item = {}\n",
    "        for key, value in item.items():\n",
    "            for _key, _value in value.items():\n",
    "                deserialized_item[key] = _value\n",
    "        return deserialized_item\n",
    "\n",
    "    def deserialize_subreddit_postID(item):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91816505-746c-4314-95ac-c8a900942e89",
   "metadata": {},
   "source": [
    "# Reddit Account Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b06066cc-4d33-40ff-b38c-aa42bb44a700",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "class RedditAccount:\n",
    "    def __init__(self, subreddit, ddb, REDDIT_ACCOUNTS_TABLE_NAME, REDDIT_AUTH_URL):\n",
    "        self.subreddit = subreddit\n",
    "        self.client_id = None\n",
    "        self.secret_key = None\n",
    "        self.username = None\n",
    "        self.password = None\n",
    "        self.auth = None\n",
    "        self.headers = {\"User-Agent\": f\"{subreddit}API/0.0.1\"}\n",
    "        self.data = {\"grant_type\": \"password\", \"username\": None, \"password\": None}\n",
    "        self.access_token = None\n",
    "        self.ddb = ddb\n",
    "\n",
    "        # Prepare this object for fetching posts.\n",
    "        self.__fetch_and_update_account_details(\n",
    "            REDDIT_ACCOUNTS_TABLE_NAME=REDDIT_ACCOUNTS_TABLE_NAME\n",
    "        )\n",
    "        self.__authenticate_with_api()\n",
    "        self.__fetch_and_update_access_token(REDDIT_AUTH_URL=REDDIT_AUTH_URL)\n",
    "\n",
    "    def key(self):\n",
    "        return {\"PK\": {\"S\": self.subreddit}}\n",
    "\n",
    "    def __fetch_and_update_account_details(self, REDDIT_ACCOUNTS_TABLE_NAME):\n",
    "        try:\n",
    "            response = self.ddb.get_item(\n",
    "                TableName=REDDIT_ACCOUNTS_TABLE_NAME, Key=self.key()\n",
    "            )\n",
    "            item = RedditAccount.deserialize_item(response[\"Item\"])\n",
    "            self.client_id = item[\"personal_use_script\"]\n",
    "            self.secret_key = item[\"secret_key\"]\n",
    "            self.username = item[\"username\"]\n",
    "            self.password = item[\"password\"]\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed with exception: {e}\")\n",
    "\n",
    "        self.data[\"username\"] = self.username\n",
    "        self.data[\"password\"] = self.password\n",
    "\n",
    "    @staticmethod\n",
    "    def deserialize_item(item):\n",
    "        new_item = {}\n",
    "        for key in item:\n",
    "            new_item[key] = RedditAccount.extract_value(item[key])\n",
    "\n",
    "        return new_item\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_value(dictionary):\n",
    "        data_type, value = list(dictionary.keys())[0], list(dictionary.values())[0]\n",
    "\n",
    "        if data_type == \"S\":\n",
    "            return value\n",
    "\n",
    "    def __authenticate_with_api(self):\n",
    "        self.auth = requests.auth.HTTPBasicAuth(self.client_id, self.secret_key)\n",
    "\n",
    "    def __fetch_and_update_access_token(self, REDDIT_AUTH_URL):\n",
    "        # Authorise and request for access token from Reddit API\n",
    "        res = requests.post(\n",
    "            REDDIT_AUTH_URL, auth=self.auth, data=self.data, headers=self.headers\n",
    "        )\n",
    "        self.access_token = res.json()[\"access_token\"]\n",
    "        self.headers[\"Authorization\"] = f\"bearer {self.access_token}\"\n",
    "\n",
    "    def fetch_posts_as_json(self, url, params={}):\n",
    "        res = requests.get(url, headers=self.headers, params=params)\n",
    "        return res.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a2a386-a53f-4050-91ca-3cdf03deabb0",
   "metadata": {},
   "source": [
    "# Event handler code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a4eb313-dbf7-48f1-80c5-bc7448e37c84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3, os, sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Making the current directory in which this file is in discoverable to python\n",
    "# sys.path.append(os.path.join(os.path.dirname(__file__)))\n",
    "\n",
    "from entities.DailyUpload import DailyUpload\n",
    "from entities.RedditAccount import RedditAccount\n",
    "from subreddit_groups import subreddit_groups\n",
    "\n",
    "ddb = boto3.client(\"dynamodb\", region_name=\"ap-south-1\")\n",
    "sqs = boto3.client(\"sqs\")\n",
    "\n",
    "# REDDIT_AUTH_URL = os.getenv(\"REDDIT_AUTH_URL\")\n",
    "# REDDIT_ACCOUNTS_TABLE_NAME = os.getenv(\"REDDIT_ACCOUNTS_TABLE_NAME\")\n",
    "# DAILY_UPLOADS_TABLE = os.getenv(\"DAILY_UPLOADS_TABLE_NAME\")\n",
    "# PROCESS_URLS_FOR_SUBREDDIT_GROUP_QUEUE_URL = os.getenv(\n",
    "#     \"PROCESS_URLS_FOR_SUBREDDIT_GROUP_QUEUE_URL\"\n",
    "# )\n",
    "\n",
    "\n",
    "def run(event, context):\n",
    "\n",
    "    # TODO: Hardcoding subreddit value for now. In production, should extract from queue:\n",
    "    # subreddit = \"funny\"\n",
    "    subreddit = str(event[\"Records\"][0][\"body\"])\n",
    "\n",
    "    # Getting from env here because, if container is warm, it will fetch from the previously\n",
    "    # executed subreddit url.\n",
    "    #TODO: Remove below line and uncomment the one below it.\n",
    "    REDDIT_API_URL_TOP = REDDIT_API_URL_TOP = \"https://oauth.reddit.com/r/placeholder_value/top\"\n",
    "#     REDDIT_API_URL_TOP = os.getenv(\"REDDIT_API_URL_TOP\")\n",
    "    REDDIT_API_URL_TOP = REDDIT_API_URL_TOP.replace(\"placeholder_value\", subreddit)\n",
    "\n",
    "    daily_upload = DailyUpload(subreddit=subreddit)\n",
    "    reddit_account = RedditAccount(\n",
    "        subreddit=subreddit,\n",
    "        ddb=ddb,\n",
    "        REDDIT_ACCOUNTS_TABLE_NAME=REDDIT_ACCOUNTS_TABLE_NAME,\n",
    "        REDDIT_AUTH_URL=REDDIT_AUTH_URL,\n",
    "    )\n",
    "\n",
    "    print(f\"Subreddit : {subreddit} is being processed\")\n",
    "\n",
    "    # Keep fetching and parsing posts from reddit api till daily_upload.total_duration\n",
    "    # is more than 600 seconds. Will use the 'after' param to keep going backwards.\n",
    "    after = None\n",
    "    while daily_upload.total_duration < 601:\n",
    "        print(f\"Fetching {subreddit} posts after {after}\")\n",
    "        posts = reddit_account.fetch_posts_as_json(\n",
    "            REDDIT_API_URL_TOP, params={\"limit\": \"100\", \"after\": after}\n",
    "        )\n",
    "        daily_upload.parse_posts(posts)\n",
    "        after = daily_upload.latest_post[\"name\"]\n",
    "        print(\" total duration \",daily_upload.total_duration)\n",
    "        print(\" eligible posts len:  \", len(daily_upload.eligible_posts))\n",
    "\n",
    "    # After uploading this subreddits' urls, update the count of todays_subreddits_count\n",
    "    # doing this as a transaction.\n",
    "    try:\n",
    "        res = ddb.transact_write_items(\n",
    "            TransactItems=[\n",
    "                {\n",
    "                    \"Put\": {\n",
    "                        \"TableName\": DAILY_UPLOADS_TABLE,\n",
    "                        \"Item\": daily_upload.serialize_to_item(),\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"Update\": {\n",
    "                        \"TableName\": DAILY_UPLOADS_TABLE,\n",
    "                        \"Key\": {\n",
    "                            \"PK\": {\"S\": daily_upload.date},\n",
    "                            \"SK\": {\"S\": \"todays_subreddits_count\"},\n",
    "                        },\n",
    "                        \"ConditionExpression\": \"attribute_exists(PK) and attribute_exists(SK)\",\n",
    "                        \"UpdateExpression\": \"SET #count = #count + :inc\",\n",
    "                        \"ExpressionAttributeNames\": {\"#count\": \"count\"},\n",
    "                        \"ExpressionAttributeValues\": {\":inc\": {\"N\": \"1\"}},\n",
    "                    }\n",
    "                },\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        if res[\"ResponseMetadata\"][\"HTTPStatusCode\"] != 200:\n",
    "            raise Exception(\n",
    "                f\"Failed to write transaction for {subreddit} on {daily_upload.date}\"\n",
    "            )\n",
    "\n",
    "        print(f\"Successfully updated DB for {subreddit} subreddit\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return {\"error\": e}\n",
    "\n",
    "    # Prepping up for fetching todays_subreddits_count an total_subreddits_count from DailyUploads table.\n",
    "    key = daily_upload.key()\n",
    "\n",
    "    total_subreddits_key = daily_upload.key()\n",
    "    todays_subreddits_key = daily_upload.key()\n",
    "\n",
    "    total_subreddits_key[\"SK\"][\"S\"] = \"total_subreddits_count\"\n",
    "    todays_subreddits_key[\"SK\"][\"S\"] = \"todays_subreddits_count\"\n",
    "\n",
    "    try:\n",
    "        res = ddb.transact_get_items(\n",
    "            TransactItems=[\n",
    "                {\n",
    "                    \"Get\": {\n",
    "                        \"Key\": total_subreddits_key,\n",
    "                        \"TableName\": DAILY_UPLOADS_TABLE,\n",
    "                    },\n",
    "                },\n",
    "                {\n",
    "                    \"Get\": {\n",
    "                        \"Key\": todays_subreddits_key,\n",
    "                        \"TableName\": DAILY_UPLOADS_TABLE,\n",
    "                    },\n",
    "                },\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return {\"error\": e}\n",
    "\n",
    "    print(f\"{subreddit} subreddit has updated todays_subreddit_count \")\n",
    "    # Extract items from response\n",
    "    items = [response[\"Item\"] for response in res[\"Responses\"]]\n",
    "\n",
    "    # Deserialize the items and extract total_subreddits_count and todays_subreddits_count items.\n",
    "    total_subreddits_item_deserialized, todays_subreddit_item_deserialized = [\n",
    "        DailyUpload.deserialize_PK_SK_count(item) for item in items\n",
    "    ]\n",
    "\n",
    "    # If evaluates to true, then push subreddit groups to ProcessUrlsQueue\n",
    "    if (\n",
    "        total_subreddits_item_deserialized[\"count\"]\n",
    "        == todays_subreddit_item_deserialized[\"count\"]\n",
    "    ):\n",
    "        push_subreddit_groups_to_queue()\n",
    "\n",
    "        # and then send custom response to show today's urls\n",
    "        # of all subreddits have been processed.\n",
    "        return {\n",
    "            \"success\": f\"All subreddits have been processed and uploaded urls for date {daily_upload.date}.\\nPushed subreddit_groups to: {PROCESS_URLS_QUEUE_URL}\"\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        subreddit: f\"successfully processed {subreddit} for date: {daily_upload.date}\"\n",
    "    }\n",
    "\n",
    "\n",
    "def push_subreddit_groups_to_queue():\n",
    "    for group in subreddit_groups:\n",
    "        res = sqs.send_message(\n",
    "            QueueUrl=PROCESS_URLS_FOR_SUBREDDIT_GROUP_QUEUE_URL, MessageBody=group\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5625d0d-7c73-4aeb-8bf1-ce48b8f0d477",
   "metadata": {},
   "outputs": [],
   "source": [
    "event = {\"Records\": [ {\"body\": \"funny\"} ]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6528bca5-72e4-4def-a146-a9efe54ee16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subreddit : funny is being processed\n",
      "Fetching funny posts after None\n",
      " total duration  878\n",
      " eligible posts len:   15\n",
      "Successfully updated DB for funny subreddit\n",
      "funny subreddit has updated todays_subreddit_count \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'funny': 'successfully processed funny for date: 2021-08-13'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(event, {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7f8dfd-e4f7-42aa-98be-77bb8832f375",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96ce25a-a3a6-49a0-b842-f129309afa07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "203dc3cd-cc07-484e-93ea-6daa6dade353",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Pushshift api tryout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31118117-2a1f-49a6-ba21-9163a3c27bac",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PushshiftAPI' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_83811/1419533487.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mapi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPushshiftAPI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'PushshiftAPI' is not defined"
     ]
    }
   ],
   "source": [
    "api = PushshiftAPI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "bd6780af-ffbd-4d76-868e-88cd716a727a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "4d1335ff-b6f0-45fb-8bc6-efdecbe2c0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "today =  datetime.today()\n",
    "yesterday = datetime.today() - timedelta(days=1)\n",
    "day_before_yesterday = yesterday - timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "bb1d29ae-d9b8-4cf4-a259-3ef9a9a0f556",
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime(today.year, today.month, today.day, 0,0,0).timestamp()\n",
    "yesterday = datetime(yesterday.year, yesterday.month, yesterday.day,0,0,0).timestamp()\n",
    "day_before_yesterday = datetime(day_before_yesterday.year, day_before_yesterday.month, day_before_yesterday.day,0,0,0).timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f4987782-469c-449b-a215-71e1391add11",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_38920/3945883094.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch_submissions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mafter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mday_before_yesterday\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbefore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoday\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubreddit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'funny'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'url'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/work/personal/whodoesntlovereddit/.venv/lib/python3.8/site-packages/psaw/PushshiftAPI.py\u001b[0m in \u001b[0;36m_search\u001b[0;34m(self, kind, stop_condition, return_batch, dataset, **kwargs)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mendpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{dataset}/{kind}/search'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_url\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_paging\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'aggs'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'aggs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/personal/whodoesntlovereddit/.venv/lib/python3.8/site-packages/psaw/PushshiftAPI.py\u001b[0m in \u001b[0;36m_handle_paging\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_nec_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlimit\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/personal/whodoesntlovereddit/.venv/lib/python3.8/site-packages/psaw/PushshiftAPI.py\u001b[0m in \u001b[0;36m_get\u001b[0;34m(self, url, payload)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unable to connect to pushshift.io. Retrying after backoff.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impose_rate_limit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m             \u001b[0mi\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/personal/whodoesntlovereddit/.venv/lib/python3.8/site-packages/psaw/PushshiftAPI.py\u001b[0m in \u001b[0;36m_impose_rate_limit\u001b[0;34m(self, nth_request)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minterval\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Imposing rate limit, sleeping for %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0minterval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_add_nec_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpayload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    " a = list(api.search_submissions(after=day_before_yesterday, before=today, subreddit='funny', filter=['url', 'title'], limit = 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "c5525ffc-0bf2-4f0b-aba8-f9eb5db3fecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1628447400"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(day_before_yesterday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "8b94ffc6-7d9b-488d-a1eb-bd06047d62d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_pushshift_data(data_type, **kwargs):\n",
    "    \"\"\"\n",
    "    Gets data from the pushshift api.\n",
    " \n",
    "    data_type can be 'comment' or 'submission'\n",
    "    The rest of the args are interpreted as payload.\n",
    " \n",
    "    Read more: https://github.com/pushshift/api\n",
    "    \"\"\"\n",
    " \n",
    "    base_url = f\"https://api.pushshift.io/reddit/search/submission/?subreddit=funny&num_comments=>0&after={int(day_before_yesterday)}&before={int(yesterday)}&is_video=true&sort_type=score&sort=score:asc&size=100&aggs=subreddit\"\n",
    "#     payload = {}\n",
    "#     print(payload)\n",
    "    request = requests.get(base_url)\n",
    "    return request.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "7162332a-ce32-487a-91f1-729889c4332d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type=\"submission\"     # give me comments, use \"submission\" to publish something\n",
    "query=\"funny\"          # Add your query\n",
    "duration=\"1d\"          # Select the timeframe. Epoch value or Integer + \"s,m,h,d\" (i.e. \"second\", \"minute\", \"hour\", \"day\")\n",
    "size=1000               # maximum 1000 comments\n",
    "sort_type=\"score\"       # Sort by score (Accepted: \"score\", \"num_comments\", \"created_utc\")\n",
    "sort=\"desc\"             # sort descending\n",
    "aggs=\"subreddit\"        #\"author\", \"link_id\", \"created_utc\", \"subreddit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "3645ffb5-554d-47e6-a73d-f52197fb5df7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_url = f\"https://api.pushshift.io/reddit/search/submission/?subreddit=funny&num_comments=>0&over_18=false&after={int(day_before_yesterday)}&before={int(yesterday)}&is_video=true&sort_type=score&sort=score:desc&size=100&aggs=subreddit\"\n",
    "\n",
    "request = requests.get(base_url)\n",
    "b = request.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "8b29ba50-c3fd-4169-8f27-6ee104843dbf",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'all_awardings': [],\n",
       " 'allow_live_comments': False,\n",
       " 'author': 'THCv1',\n",
       " 'author_flair_css_class': None,\n",
       " 'author_flair_richtext': [],\n",
       " 'author_flair_text': None,\n",
       " 'author_flair_type': 'text',\n",
       " 'author_fullname': 't2_1bfzjru7',\n",
       " 'author_is_blocked': False,\n",
       " 'author_patreon_flair': False,\n",
       " 'author_premium': False,\n",
       " 'awarders': [],\n",
       " 'can_mod_post': False,\n",
       " 'contest_mode': False,\n",
       " 'created_utc': 1628530642,\n",
       " 'domain': '/r/funny/comments/p16ap5/we_all_have_at_least_one_in_every_town/',\n",
       " 'full_link': 'https://www.reddit.com/r/funny/comments/p16ap5/we_all_have_at_least_one_in_every_town/',\n",
       " 'gildings': {},\n",
       " 'id': 'p16ap5',\n",
       " 'is_created_from_ads_ui': False,\n",
       " 'is_crosspostable': True,\n",
       " 'is_meta': False,\n",
       " 'is_original_content': False,\n",
       " 'is_reddit_media_domain': False,\n",
       " 'is_robot_indexable': True,\n",
       " 'is_self': False,\n",
       " 'is_video': True,\n",
       " 'link_flair_background_color': '',\n",
       " 'link_flair_richtext': [],\n",
       " 'link_flair_text_color': 'dark',\n",
       " 'link_flair_type': 'text',\n",
       " 'locked': False,\n",
       " 'media_only': False,\n",
       " 'no_follow': True,\n",
       " 'num_comments': 2,\n",
       " 'num_crossposts': 0,\n",
       " 'over_18': False,\n",
       " 'parent_whitelist_status': 'all_ads',\n",
       " 'permalink': '/r/funny/comments/p16ap5/we_all_have_at_least_one_in_every_town/',\n",
       " 'pinned': False,\n",
       " 'post_hint': 'hosted:video',\n",
       " 'preview': {'enabled': False,\n",
       "  'images': [{'id': 'vAOgvqFiMXTwh_zTDxVYoYQjKaUpuIEeJx-_7z2AIYI',\n",
       "    'resolutions': [{'height': 192,\n",
       "      'url': 'https://external-preview.redd.it/ettU3c89FMAdWv87wUl7TbtDQ1VFvuElufEHbS32zxM.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=8a0ffafed2d792006bd245d18d12f9c126a28bd2',\n",
       "      'width': 108},\n",
       "     {'height': 384,\n",
       "      'url': 'https://external-preview.redd.it/ettU3c89FMAdWv87wUl7TbtDQ1VFvuElufEHbS32zxM.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=06ee404f7981edafcc8a49e484431f46ece0df6b',\n",
       "      'width': 216},\n",
       "     {'height': 569,\n",
       "      'url': 'https://external-preview.redd.it/ettU3c89FMAdWv87wUl7TbtDQ1VFvuElufEHbS32zxM.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=864c85966cfd7f72a8bcece26a3ca9460434bfbd',\n",
       "      'width': 320},\n",
       "     {'height': 1138,\n",
       "      'url': 'https://external-preview.redd.it/ettU3c89FMAdWv87wUl7TbtDQ1VFvuElufEHbS32zxM.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=580c83e23fda698f6536d10ed0cd7abe2f1f1e80',\n",
       "      'width': 640}],\n",
       "    'source': {'height': 1138,\n",
       "     'url': 'https://external-preview.redd.it/ettU3c89FMAdWv87wUl7TbtDQ1VFvuElufEHbS32zxM.png?format=pjpg&amp;auto=webp&amp;s=fc62ec2e7fdff83a195901e639fcead64f4fa4cd',\n",
       "     'width': 640},\n",
       "    'variants': {}}]},\n",
       " 'pwls': 6,\n",
       " 'retrieved_on': 1628530653,\n",
       " 'score': 1,\n",
       " 'selftext': '',\n",
       " 'send_replies': True,\n",
       " 'spoiler': False,\n",
       " 'stickied': False,\n",
       " 'subreddit': 'funny',\n",
       " 'subreddit_id': 't5_2qh33',\n",
       " 'subreddit_subscribers': 37027212,\n",
       " 'subreddit_type': 'public',\n",
       " 'thumbnail': 'https://b.thumbs.redditmedia.com/G_APlm8C9KTmR2pB6ebbD5VTrVijqTmm8U4guAZTCsM.jpg',\n",
       " 'thumbnail_height': 140,\n",
       " 'thumbnail_width': 140,\n",
       " 'title': 'We all have at least one in every town',\n",
       " 'total_awards_received': 0,\n",
       " 'treatment_tags': [],\n",
       " 'upvote_ratio': 1.0,\n",
       " 'url': 'https://v.redd.it/lf1rp8m1cdg71',\n",
       " 'url_overridden_by_dest': 'https://v.redd.it/lf1rp8m1cdg71',\n",
       " 'whitelist_status': 'all_ads',\n",
       " 'wls': 6}"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b['data'][59]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "d9f08483-3dd1-4000-b8bd-f14bd76c31de",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 'all_awardings': [],\n",
      "  'allow_live_comments': False,\n",
      "  'author': 'Tinzeii',\n",
      "  'author_flair_css_class': None,\n",
      "  'author_flair_richtext': [],\n",
      "  'author_flair_text': None,\n",
      "  'author_flair_type': 'text',\n",
      "  'author_fullname': 't2_4fknz7x5',\n",
      "  'author_is_blocked': False,\n",
      "  'author_patreon_flair': False,\n",
      "  'author_premium': False,\n",
      "  'awarders': [],\n",
      "  'can_mod_post': False,\n",
      "  'contest_mode': False,\n",
      "  'created_utc': 1628460924,\n",
      "  'domain': '/r/funny/comments/p0o96c/enjoy_ittt/',\n",
      "  'full_link': 'https://www.reddit.com/r/funny/comments/p0o96c/enjoy_ittt/',\n",
      "  'gildings': {},\n",
      "  'id': 'p0o96c',\n",
      "  'is_created_from_ads_ui': False,\n",
      "  'is_crosspostable': True,\n",
      "  'is_meta': False,\n",
      "  'is_original_content': False,\n",
      "  'is_reddit_media_domain': False,\n",
      "  'is_robot_indexable': True,\n",
      "  'is_self': False,\n",
      "  'is_video': True,\n",
      "  'link_flair_background_color': '',\n",
      "  'link_flair_richtext': [],\n",
      "  'link_flair_text_color': 'dark',\n",
      "  'link_flair_type': 'text',\n",
      "  'locked': False,\n",
      "  'media_only': False,\n",
      "  'no_follow': True,\n",
      "  'num_comments': 7,\n",
      "  'num_crossposts': 0,\n",
      "  'over_18': False,\n",
      "  'parent_whitelist_status': 'all_ads',\n",
      "  'permalink': '/r/funny/comments/p0o96c/enjoy_ittt/',\n",
      "  'pinned': False,\n",
      "  'post_hint': 'hosted:video',\n",
      "  'preview': { 'enabled': False,\n",
      "               'images': [ { 'id': '6mv1fxeMmZ2xCVEabIIIt0ou6y20b1yGfacQ8SVYUpQ',\n",
      "                             'resolutions': [ { 'height': 61,\n",
      "                                                'url': 'https://external-preview.redd.it/HeZqDKS-OI37QFKtiE4pefNCF7KY-c_Rj6jhrRsFJUU.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=29d65e4c8318b389aa9a01323933e9a00585046b',\n",
      "                                                'width': 108},\n",
      "                                              { 'height': 123,\n",
      "                                                'url': 'https://external-preview.redd.it/HeZqDKS-OI37QFKtiE4pefNCF7KY-c_Rj6jhrRsFJUU.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=f746091c8bba12f603a0a2c6aa58e7f93ae324bc',\n",
      "                                                'width': 216},\n",
      "                                              { 'height': 182,\n",
      "                                                'url': 'https://external-preview.redd.it/HeZqDKS-OI37QFKtiE4pefNCF7KY-c_Rj6jhrRsFJUU.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=7c073116b0f276155972bcafb1890b9c0ca010b5',\n",
      "                                                'width': 320}],\n",
      "                             'source': { 'height': 360,\n",
      "                                         'url': 'https://external-preview.redd.it/HeZqDKS-OI37QFKtiE4pefNCF7KY-c_Rj6jhrRsFJUU.png?format=pjpg&amp;auto=webp&amp;s=cdd535aa180d6d3e23b127a2cbc5786f85a15763',\n",
      "                                         'width': 632},\n",
      "                             'variants': {}}]},\n",
      "  'pwls': 6,\n",
      "  'retrieved_on': 1628460935,\n",
      "  'score': 1,\n",
      "  'selftext': '',\n",
      "  'send_replies': True,\n",
      "  'spoiler': False,\n",
      "  'stickied': False,\n",
      "  'subreddit': 'funny',\n",
      "  'subreddit_id': 't5_2qh33',\n",
      "  'subreddit_subscribers': 37020145,\n",
      "  'subreddit_type': 'public',\n",
      "  'thumbnail': 'https://b.thumbs.redditmedia.com/wv4qckXFfUECxxUgnDdBHsSm_dgy80OdDMdkCr63m3Y.jpg',\n",
      "  'thumbnail_height': 79,\n",
      "  'thumbnail_width': 140,\n",
      "  'title': 'Enjoy ittt😂',\n",
      "  'total_awards_received': 0,\n",
      "  'treatment_tags': [],\n",
      "  'upvote_ratio': 1.0,\n",
      "  'url': 'https://v.redd.it/q7l6j9uvk7g71',\n",
      "  'url_overridden_by_dest': 'https://v.redd.it/q7l6j9uvk7g71',\n",
      "  'whitelist_status': 'all_ads',\n",
      "  'wls': 6}\n"
     ]
    }
   ],
   "source": [
    "for post in a['data']:    \n",
    "    pp.pprint(post)\n",
    "    break\n",
    "\n",
    "   \n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "922df849-2007-41e7-869d-9a3cd2d06835",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'all_awardings': [],\n",
       " 'allow_live_comments': False,\n",
       " 'author': 'Tinzeii',\n",
       " 'author_flair_css_class': None,\n",
       " 'author_flair_richtext': [],\n",
       " 'author_flair_text': None,\n",
       " 'author_flair_type': 'text',\n",
       " 'author_fullname': 't2_4fknz7x5',\n",
       " 'author_is_blocked': False,\n",
       " 'author_patreon_flair': False,\n",
       " 'author_premium': False,\n",
       " 'awarders': [],\n",
       " 'can_mod_post': False,\n",
       " 'contest_mode': False,\n",
       " 'created_utc': 1628460924,\n",
       " 'domain': '/r/funny/comments/p0o96c/enjoy_ittt/',\n",
       " 'full_link': 'https://www.reddit.com/r/funny/comments/p0o96c/enjoy_ittt/',\n",
       " 'gildings': {},\n",
       " 'id': 'p0o96c',\n",
       " 'is_created_from_ads_ui': False,\n",
       " 'is_crosspostable': True,\n",
       " 'is_meta': False,\n",
       " 'is_original_content': False,\n",
       " 'is_reddit_media_domain': False,\n",
       " 'is_robot_indexable': True,\n",
       " 'is_self': False,\n",
       " 'is_video': True,\n",
       " 'link_flair_background_color': '',\n",
       " 'link_flair_richtext': [],\n",
       " 'link_flair_text_color': 'dark',\n",
       " 'link_flair_type': 'text',\n",
       " 'locked': False,\n",
       " 'media_only': False,\n",
       " 'no_follow': True,\n",
       " 'num_comments': 7,\n",
       " 'num_crossposts': 0,\n",
       " 'over_18': False,\n",
       " 'parent_whitelist_status': 'all_ads',\n",
       " 'permalink': '/r/funny/comments/p0o96c/enjoy_ittt/',\n",
       " 'pinned': False,\n",
       " 'post_hint': 'hosted:video',\n",
       " 'preview': {'enabled': False,\n",
       "  'images': [{'id': '6mv1fxeMmZ2xCVEabIIIt0ou6y20b1yGfacQ8SVYUpQ',\n",
       "    'resolutions': [{'height': 61,\n",
       "      'url': 'https://external-preview.redd.it/HeZqDKS-OI37QFKtiE4pefNCF7KY-c_Rj6jhrRsFJUU.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=29d65e4c8318b389aa9a01323933e9a00585046b',\n",
       "      'width': 108},\n",
       "     {'height': 123,\n",
       "      'url': 'https://external-preview.redd.it/HeZqDKS-OI37QFKtiE4pefNCF7KY-c_Rj6jhrRsFJUU.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=f746091c8bba12f603a0a2c6aa58e7f93ae324bc',\n",
       "      'width': 216},\n",
       "     {'height': 182,\n",
       "      'url': 'https://external-preview.redd.it/HeZqDKS-OI37QFKtiE4pefNCF7KY-c_Rj6jhrRsFJUU.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=7c073116b0f276155972bcafb1890b9c0ca010b5',\n",
       "      'width': 320}],\n",
       "    'source': {'height': 360,\n",
       "     'url': 'https://external-preview.redd.it/HeZqDKS-OI37QFKtiE4pefNCF7KY-c_Rj6jhrRsFJUU.png?format=pjpg&amp;auto=webp&amp;s=cdd535aa180d6d3e23b127a2cbc5786f85a15763',\n",
       "     'width': 632},\n",
       "    'variants': {}}]},\n",
       " 'pwls': 6,\n",
       " 'retrieved_on': 1628460935,\n",
       " 'score': 1,\n",
       " 'selftext': '',\n",
       " 'send_replies': True,\n",
       " 'spoiler': False,\n",
       " 'stickied': False,\n",
       " 'subreddit': 'funny',\n",
       " 'subreddit_id': 't5_2qh33',\n",
       " 'subreddit_subscribers': 37020145,\n",
       " 'subreddit_type': 'public',\n",
       " 'thumbnail': 'https://b.thumbs.redditmedia.com/wv4qckXFfUECxxUgnDdBHsSm_dgy80OdDMdkCr63m3Y.jpg',\n",
       " 'thumbnail_height': 79,\n",
       " 'thumbnail_width': 140,\n",
       " 'title': 'Enjoy ittt😂',\n",
       " 'total_awards_received': 0,\n",
       " 'treatment_tags': [],\n",
       " 'upvote_ratio': 1.0,\n",
       " 'url': 'https://v.redd.it/q7l6j9uvk7g71',\n",
       " 'url_overridden_by_dest': 'https://v.redd.it/q7l6j9uvk7g71',\n",
       " 'whitelist_status': 'all_ads',\n",
       " 'wls': 6}"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c136a5-271f-49c5-8336-8f1f4f540a27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python3810jvsc74a57bd024b555649d86f360bc29675e4ea05747664583e96f16283f97272f664e30bb4e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
